# -*- coding: utf-8 -*-
"""ì°X7ë§‰.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OynZYfJyrKAyTb7fwLFJf86VLgwb3n4F
"""

import os
import shutil
import random
import yaml
import xml.etree.ElementTree as ET
from pathlib import Path
import kagglehub
import pandas as pd
import numpy as np
import cv2
from concurrent.futures import ProcessPoolExecutor
from tqdm import tqdm
import zipfile


print("1. ê³ ì† ì²˜ë¦¬ë¥¼ ìœ„í•œ í™˜ê²½ ì„¤ì • (Colab ë¡œì»¬ ì‚¬ìš©)")


from google.colab import drive
drive.mount('/content/drive', force_remount=True)


workspace_root = Path('/content/workspace')
if workspace_root.exists():
    shutil.rmtree(workspace_root)
workspace_root.mkdir(parents=True, exist_ok=True)


drive_save_dir = Path('/content/drive/MyDrive/PCB_defect_detection_Project')
drive_save_dir.mkdir(parents=True, exist_ok=True)

print(f"ì‘ì—… ê³µê°„ ìƒì„± ì™„ë£Œ: {workspace_root}")


print("\n2. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ (Kaggle -> Colab Local)")
dataset_name = 'akhatova/pcb-defects'
kaggle_download_path = Path(kagglehub.dataset_download(dataset_name))
raw_dataset_path = workspace_root / 'raw_data'


shutil.copytree(kaggle_download_path / 'PCB_DATASET', raw_dataset_path, dirs_exist_ok=True)

images_dir = raw_dataset_path / 'images'
annot_dir = raw_dataset_path / 'Annotations'
print("ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ.\n")


print("3. XML ì–´ë…¸í…Œì´ì…˜ íŒŒì‹±")
def parse_xml(xml_file):
    tree = ET.parse(xml_file)
    root = tree.getroot()
    filename = root.find('filename').text
    width = int(root.find('size/width').text)
    height = int(root.find('size/height').text)
    data = []
    for obj in root.findall('object'):
        name = obj.find('name').text
        xmin = int(obj.find('bndbox/xmin').text)
        ymin = int(obj.find('bndbox/ymin').text)
        xmax = int(obj.find('bndbox/xmax').text)
        ymax = int(obj.find('bndbox/ymax').text)
        data.append({
            'filename': filename, 'width': width, 'height': height,
            'class': name, 'xmin': xmin, 'ymin': ymin, 'xmax': xmax, 'ymax': ymax
        })
    return data

xml_file_paths = list(annot_dir.rglob('*.xml'))

df_list = [pd.DataFrame(parse_xml(p)) for p in xml_file_paths]
annot_df = pd.concat(df_list, ignore_index=True)
print(f"ì´ {len(annot_df)}ê°œì˜ ê°ì²´ íŒŒì‹± ì™„ë£Œ.")

print("\n4. ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì´ìš©í•œ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ë° ì¢Œí‘œ ë³€í™˜")

def process_single_image(args):
    """ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë‹¨ìœ„ ì‘ì—… í•¨ìˆ˜"""
    row, input_dir, output_dir, target_size = args


    try:
        image_path = list(input_dir.rglob(row['filename']))[0]
        image = cv2.imread(str(image_path))

        if image is None:
            return None

        resized_image = cv2.resize(image, target_size)
        output_path = output_dir / row['filename']
        cv2.imwrite(str(output_path), resized_image)

        w_ratio = target_size[0] / row['width']
        h_ratio = target_size[1] / row['height']

        return {
            'filename': row['filename'],
            'width': target_size[0], 'height': target_size[1],
            'class': row['class'],
            'xmin': int(row['xmin'] * w_ratio), 'ymin': int(row['ymin'] * h_ratio),
            'xmax': int(row['xmax'] * w_ratio), 'ymax': int(row['ymax'] * h_ratio)
        }
    except Exception as e:
        return None

resized_img_dir = workspace_root / 'images_resized'
resized_img_dir.mkdir(parents=True, exist_ok=True)


unique_files = annot_df[['filename', 'width', 'height']].drop_duplicates()
resize_tasks = []

for _, row in unique_files.iterrows():
    resize_tasks.append((row, images_dir, resized_img_dir, (640, 640)))

print(f"ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ì‘ì—… ì‹œì‘ ({len(resize_tasks)}ì¥)... CPU ì½”ì–´ ì‚¬ìš©")


with ProcessPoolExecutor() as executor:

    list(tqdm(executor.map(process_single_image, resize_tasks), total=len(resize_tasks)))


annot_df_resized = annot_df.copy()
annot_df_resized['xmin'] = (annot_df_resized['xmin'] * (640 / annot_df_resized['width'])).astype(int)
annot_df_resized['xmax'] = (annot_df_resized['xmax'] * (640 / annot_df_resized['width'])).astype(int)
annot_df_resized['ymin'] = (annot_df_resized['ymin'] * (640 / annot_df_resized['height'])).astype(int)
annot_df_resized['ymax'] = (annot_df_resized['ymax'] * (640 / annot_df_resized['height'])).astype(int)
annot_df_resized['width'] = 640
annot_df_resized['height'] = 640

print("ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ.")


print("\n5. ë°ì´í„°ì…‹ ë¶„í•  ë° YOLO ë¼ë²¨ ìƒì„±")

classes = ['missing_hole', 'mouse_bite', 'open_circuit', 'short', 'spur', 'spurious_copper']


def create_yolo_labels_vectorized(df, classes):
    df['class_id'] = df['class'].apply(lambda x: classes.index(x.lower()))
    df['x_center'] = ((df['xmin'] + df['xmax']) / 2) / df['width']
    df['y_center'] = ((df['ymin'] + df['ymax']) / 2) / df['height']
    df['bbox_w'] = (df['xmax'] - df['xmin']) / df['width']
    df['bbox_h'] = (df['ymax'] - df['ymin']) / df['height']
    return df

yolo_df = create_yolo_labels_vectorized(annot_df_resized, classes)

output_dir_processed = workspace_root / 'data_processed'
for split in ['train', 'val', 'test']:
    (output_dir_processed / 'images' / split).mkdir(parents=True, exist_ok=True)
    (output_dir_processed / 'labels' / split).mkdir(parents=True, exist_ok=True)


unique_filenames = yolo_df['filename'].unique()
np.random.shuffle(unique_filenames)

train_end = int(len(unique_filenames) * 0.8)
val_end = train_end + int(len(unique_filenames) * 0.1)

splits = {
    'train': unique_filenames[:train_end],
    'val': unique_filenames[train_end:val_end],
    'test': unique_filenames[val_end:]
}

print("íŒŒì¼ ì´ë™ ë° ë¼ë²¨ íŒŒì¼ ìƒì„± ì¤‘...")
for split, filenames in splits.items():
    for fname in tqdm(filenames, desc=f"Processing {split}"):

        src_img = resized_img_dir / fname
        dst_img = output_dir_processed / 'images' / split / fname
        if src_img.exists():
            shutil.copy(src_img, dst_img)


        file_objects = yolo_df[yolo_df['filename'] == fname]
        label_path = output_dir_processed / 'labels' / split / f"{Path(fname).stem}.txt"

        with open(label_path, 'w') as f:
            for _, row in file_objects.iterrows():
                f.write(f"{int(row['class_id'])} {row['x_center']:.6f} {row['y_center']:.6f} {row['bbox_w']:.6f} {row['bbox_h']:.6f}\n")

import os
import shutil
from pathlib import Path

print("\n6. ê²°ê³¼ë¬¼ ì••ì¶• ë° ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ (ìˆ˜ì •ë¨)")


workspace_root = Path('/content/workspace')
output_dir_processed = workspace_root / 'data_processed'
drive_save_dir = Path('/content/drive/MyDrive/PCB_defect_detection_Project')


base_name = workspace_root / 'data_processed'
shutil.make_archive(str(base_name), 'zip', output_dir_processed)


generated_zip = workspace_root / 'data_processed.zip'
final_dest = drive_save_dir / 'data_processed.zip'


if not drive_save_dir.exists():
    print(f" ê²½ê³ : ë“œë¼ì´ë¸Œ í´ë”ê°€ ì—†ì–´ì„œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤: {drive_save_dir}")
    drive_save_dir.mkdir(parents=True, exist_ok=True)


if generated_zip.exists():
    try:
        shutil.copy(str(generated_zip), final_dest)
        print(f" ëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ê²°ê³¼ë¬¼(Zip)ì´ êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {final_dest}")


        size_mb = os.path.getsize(final_dest) / (1024 * 1024)
        print(f"ì €ì¥ëœ íŒŒì¼ í¬ê¸°: {size_mb:.2f} MB")

    except Exception as e:
        print(f" ë³µì‚¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        print("êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ê°€ ëŠê²¼ê±°ë‚˜, ê¶Œí•œ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
else:
    print(f" ì˜¤ë¥˜: ì••ì¶• íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: {generated_zip}")

!pip install ultralytics
import zipfile
import os
from pathlib import Path
import shutil
from ultralytics import YOLO


project_root = Path('/content/drive/MyDrive/PCB_defect_detection_Project')
zip_file_path = project_root / 'data_processed.zip'
extract_path = Path('/content/dataset')


print(f" ì••ì¶• íŒŒì¼ í™•ì¸ ì¤‘: {zip_file_path}")

if not zip_file_path.exists():
    print(f" ì˜¤ë¥˜: {zip_file_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("íŒŒì¼ ì´ë¦„ì´ ì •í™•í•œì§€, .zip í™•ì¥ìê°€ ë¶™ì–´ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    print(" ì••ì¶• í•´ì œ ì‹œì‘ (Colab ë¡œì»¬ ê³µê°„ìœ¼ë¡œ)...")

    if extract_path.exists():
        shutil.rmtree(extract_path)
    extract_path.mkdir(parents=True, exist_ok=True)

    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)
    print(" ì••ì¶• í•´ì œ ì™„ë£Œ!")


dataset_root = extract_path
if (extract_path / 'data_processed').exists():
    dataset_root = extract_path / 'data_processed'

print(f"ğŸ“ ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ: {dataset_root}")


if not (dataset_root / 'images/val').exists():

    if (dataset_root / 'images/valid').exists():
        val_dir = 'images/valid'
        print("â„¹ ì•Œë¦¼: 'val' ëŒ€ì‹  'valid' í´ë”ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    elif (dataset_root / 'images/test').exists():
        val_dir = 'images/test'
        print("â„¹ ì•Œë¦¼: 'val' ëŒ€ì‹  'test' í´ë”ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:

        val_dir = 'images/train'
        print(" ê²½ê³ : ê²€ì¦ìš© í´ë”ë¥¼ ì°¾ì§€ ëª»í•´ 'images/train'ì„ ê²€ì¦ìš©ìœ¼ë¡œ í•¨ê»˜ ì‚¬ìš©í•©ë‹ˆë‹¤.")
else:
    val_dir = 'images/val'



print("===== data.yaml íŒŒì¼ ìƒì„± =====")

classes = ['missing_hole', 'mouse_bite', 'open_circuit',
           'short', 'spur', 'spurious_copper']

all_data_yaml_content = f"""
path: {dataset_root.as_posix()}
train: images/train
val: {val_dir}
names:
  0: {classes[0]}
  1: {classes[1]}
  2: {classes[2]}
  3: {classes[3]}
  4: {classes[4]}
  5: {classes[5]}
"""


yaml_path = project_root / 'data.yaml'
with open(yaml_path, 'w') as f:
    f.write(all_data_yaml_content)
print(f"data.yaml ì €ì¥ ì™„ë£Œ: {yaml_path}")



print("\n===== ëª¨ë¸ í•™ìŠµ ì‹œì‘ =====")
results_base_dir_colab = Path('/content/pcb_results')
dest_results_dir_drive = project_root / 'results'

model = YOLO('yolo11s.pt')

try:
    results = model.train(
        data=str(yaml_path),
        epochs=100,
        batch=16,
        imgsz=640,
        project=str(results_base_dir_colab),
        name='yolo11s_run',
        exist_ok=True,
        hsv_h=0.0,
        hsv_s=0.0,
        hsv_v=0.0,
        degrees=10.0,
        fliplr=0.0,
        mixup=0.3
    )


    print(" í•™ìŠµ ê²°ê³¼ë¥¼ Google Driveë¡œ ë³µì‚¬ ì¤‘...")
    source_dir = results_base_dir_colab / 'yolo11s_run'
    dest_dir = dest_results_dir_drive / 'yolo11s_run'
    shutil.copytree(source_dir, dest_dir, dirs_exist_ok=True)
    print(f" ëª¨ë“  ê³¼ì • ì™„ë£Œ! ê²°ê³¼ ìœ„ì¹˜: {dest_dir}")

except Exception as e:
    print(f"\n í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path


print("\n===== 4. í•™ìŠµ ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥ =====")


results_dir_colab = Path('/content/pcb_results') / 'yolo11s_run'


results_csv_path = results_dir_colab / 'results.csv'

if results_csv_path.exists():

    results_df = pd.read_csv(results_csv_path)


    results_df.columns = results_df.columns.str.strip()


    epochs = results_df['epoch']
    train_box_loss = results_df['train/box_loss']
    val_box_loss = results_df['val/box_loss']
    train_cls_loss = results_df['train/cls_loss']
    val_cls_loss = results_df['val/cls_loss']
    train_dfl_loss = results_df['train/dfl_loss']
    val_dfl_loss = results_df['val/dfl_loss']


    fig, axs = plt.subplots(1, 3, figsize=(18, 6))


    axs[0].plot(epochs, train_box_loss, label='Train Box Loss', color='blue')
    axs[0].plot(epochs, val_box_loss, label='Validation Box Loss', color='orange')
    axs[0].set_title('Box Loss')
    axs[0].set_xlabel('Epoch')
    axs[0].set_ylabel('Loss')
    axs[0].legend()
    axs[0].grid(True)


    axs[1].plot(epochs, train_cls_loss, label='Train Cls Loss', color='blue')
    axs[1].plot(epochs, val_cls_loss, label='Validation Cls Loss', color='orange')
    axs[1].set_title('Class Loss')
    axs[1].set_xlabel('Epoch')
    axs[1].set_ylabel('Loss')
    axs[1].legend()
    axs[1].grid(True)


    axs[2].plot(epochs, train_dfl_loss, label='Train Dfl Loss', color='blue')
    axs[2].plot(epochs, val_dfl_loss, label='Validation Dfl Loss', color='orange')
    axs[2].set_title('Distribution Focal Loss')
    axs[2].set_xlabel('Epoch')
    axs[2].set_ylabel('Loss')
    axs[2].legend()
    axs[2].grid(True)

    plt.tight_layout()
    plt.show()
else:
    print(f" ì˜¤ë¥˜: {results_csv_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµ ê²°ê³¼ í´ë”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from pathlib import Path
import glob


print("\n===== 4. í•™ìŠµ ê²°ê³¼ ìë™ ì‹œê°í™” (ìƒì„±ëœ ì´ë¯¸ì§€ ë¡œë“œ) =====")

def show_result_image(image_path, title="Result Image", figsize=(12, 10)):
    """ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°›ì•„ Matplotlibìœ¼ë¡œ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜"""
    if image_path.exists():
        img = mpimg.imread(str(image_path))
        plt.figure(figsize=figsize)
        plt.imshow(img)
        plt.title(title, fontsize=15, fontweight='bold')
        plt.axis('off')
        plt.show()
        print(f" ì¶œë ¥ ì™„ë£Œ: {title}")
    else:
        print(f" íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {title} ({image_path.name})")


current_result_dir = results_dir_colab

print(f" ê²°ê³¼ íŒŒì¼ ì½ê¸° ê²½ë¡œ: {current_result_dir}")


show_result_image(current_result_dir / 'results.png', title="Training Results Summary (Loss & Metrics)")


cm_path = current_result_dir / 'confusion_matrix_normalized.png'
if not cm_path.exists():
    cm_path = current_result_dir / 'confusion_matrix.png'
show_result_image(cm_path, title="Confusion Matrix")

show_result_image(current_result_dir / 'BoxPR_curve.png', title="Precision-Recall Curve")


show_result_image(current_result_dir / 'BoxF1_curve.png', title="F1 Score Curve")


pred_images = sorted(list(current_result_dir.glob('val_batch*_pred.jpg')))

if pred_images:
    print(f"\n=====  ì‹¤ì œ ê²€ì¦ ì´ë¯¸ì§€ ì˜ˆì¸¡ ê²°ê³¼ ({len(pred_images)}ì¥ ì¤‘ 3ì¥) =====")
    for i, img_path in enumerate(pred_images[:3]):
        show_result_image(img_path, title=f"Validation Prediction Sample #{i+1}", figsize=(15, 15))
else:
    print("\n ê²€ì¦ ì˜ˆì¸¡ ì´ë¯¸ì§€(val_batch*_pred.jpg)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

print("\n===== ëª¨ë“  ì‹œê°í™” ì™„ë£Œ =====")

import yaml
from pathlib import Path
from ultralytics import YOLO
import matplotlib.pyplot as plt
import matplotlib.image as mpimg


project_root = Path('/content/drive/MyDrive/PCB_defect_detection_Project')


yaml_file_path = project_root / 'data.yaml'



print(f" í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
print(f" ì„¤ì • íŒŒì¼: {yaml_file_path}")

if not yaml_file_path.exists():
    print(f" ì˜¤ë¥˜: {yaml_file_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ê°€ ë˜ì–´ ìˆëŠ”ì§€, ê²½ë¡œê°€ ì •í™•í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:

    with open(yaml_file_path, 'r') as f:
        data = yaml.safe_load(f)


    data['test'] = 'images/test'


    with open(yaml_file_path, 'w') as f:
        yaml.dump(data, f)

    print(f" data.yamlì— Test ê²½ë¡œê°€ ì„±ê³µì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")



    print("\n êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ Test ì„±ëŠ¥ ê²€ì¦ ì‹œì‘...")

    metrics = model.val(data=str(yaml_file_path), split='test', plots=True)


    save_dir = Path(metrics.save_dir)
    cm_path = save_dir / 'confusion_matrix.png'
    cm_norm_path = save_dir / 'confusion_matrix_normalized.png'

    def show_result_image(img_path, title):
        if img_path.exists():
            img = mpimg.imread(str(img_path))
            plt.figure(figsize=(12, 10))
            plt.imshow(img)
            plt.title(title, fontsize=15)
            plt.axis('off')
            plt.show()
        else:
            print(f" ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")

    print(f"\n=== ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ: {save_dir} ===")
    show_result_image(cm_path, "Confusion Matrix (Test Set)")
    show_result_image(cm_norm_path, "Normalized Confusion Matrix (Test Set)")

    print(f"\nTest Set mAP50: {metrics.box.map50:.4f}")

import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from pathlib import Path


save_dir = Path('/content/runs/detect/val4')

print(f" í´ë” í™•ì¸ ì¤‘: {save_dir}")

if not save_dir.exists():
    print(" ì˜¤ë¥˜: í•´ë‹¹ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:

    all_files = os.listdir(save_dir)
    print(f" ìƒì„±ëœ íŒŒì¼ ëª©ë¡: {all_files}")


    image_files = [f for f in all_files if f.endswith('.png') or f.endswith('.jpg')]

    if not image_files:
        print(" ê²½ê³ : ì´ í´ë” ì•ˆì— ì´ë¯¸ì§€ íŒŒì¼ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f"\n ì´ {len(image_files)}ê°œì˜ ê·¸ë˜í”„ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì¶œë ¥ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")

        for img_file in image_files:


            img_path = save_dir / img_file
            img = mpimg.imread(str(img_path))

            plt.figure(figsize=(12, 10))
            plt.imshow(img)
            plt.title(img_file, fontsize=15, fontweight='bold')
            plt.axis('off')
            plt.show()

