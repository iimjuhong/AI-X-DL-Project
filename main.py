# -*- coding: utf-8 -*-
"""
PCB ê²°í•¨ íƒì§€ - ë©”ì¸ ì‹¤í–‰ íŒŒì¼
YOLOv11 ê¸°ë°˜ PCB ê¸°íŒ ê²°í•¨ ìë™ íƒì§€ ì‹œìŠ¤í…œ

Authors: ì„ì£¼í™, ì •ëª…ì¬
Date: 2024
"""

import sys
from pathlib import Path
import argparse


def print_header():
    """í”„ë¡œê·¸ë¨ í—¤ë” ì¶œë ¥"""
    print("\n" + "=" * 60)
    print(" " * 15 + "PCB ê²°í•¨ íƒì§€ ì‹œìŠ¤í…œ")
    print(" " * 12 + "YOLOv11 ê¸°ë°˜ ìë™í™” ê²€ì‚¬")
    print("=" * 60)
    print("\nğŸ‘¥ Authors: ì„ì£¼í™, ì •ëª…ì¬")
    print("ğŸ“… Project: PCB Defect Detection using YOLO")
    print("=" * 60)

def print_section(title):
    """ì„¹ì…˜ êµ¬ë¶„ ì¶œë ¥"""
    print(f"\n{'#' * (len(title) + 6)}")
    print(f"## {title} ##")
    print(f"{'#' * (len(title) + 6)}")

def print_info(message):
    """ì •ë³´ ë©”ì‹œì§€ ì¶œë ¥"""
    print(f"[INFO] {message}")

def print_warning(message):
    """ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥"""
    print(f"[WARN] {message}")

def print_error(message):
    """ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥"""
    print(f"[ERROR] {message}")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

try:
    from config import Config
    from data import DataDownloader, DataPreprocessor, DatasetSplitter
    from models import ModelTrainer, ModelEvaluator, ModelInference
    from utils import Visualizer, FileUtils
except ImportError as e:
    print_error(f"í•„ìš”í•œ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”: {e}")
    sys.exit(1)


def parse_arguments():
    """ì»¤ë§¨ë“œ ë¼ì¸ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description='PCB ê²°í•¨ íƒì§€ ì‹œìŠ¤í…œ - YOLOv11 ê¸°ë°˜ ìë™í™” ê²€ì‚¬'
    )
    
    parser.add_argument(
        '--skip-download', action='store_true', help='ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°'
    )
    parser.add_argument(
        '--skip-preprocessing', action='store_true', help='ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°'
    )
    parser.add_argument(
        '--skip-training', action='store_true', help='ëª¨ë¸ í•™ìŠµ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°'
    )
    parser.add_argument(
        '--skip-visualization', action='store_true', help='ì‹œê°í™” ë‹¨ê³„ ê±´ë„ˆë›°ê¸°'
    )
    parser.add_argument(
        '--only-evaluate', action='store_true', help='í‰ê°€ë§Œ ìˆ˜í–‰ (ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©)'
    )
    parser.add_argument(
        '--model-path', type=str, default=None, help='í‰ê°€ ë° ì¶”ë¡ ì— ì‚¬ìš©í•  ëª¨ë¸ ê²½ë¡œ'
    )
    parser.add_argument(
        '--epochs', type=int, default=None, help='í•™ìŠµ ì—í¬í¬ ìˆ˜ (ê¸°ë³¸ê°’: config.py ì°¸ì¡°)'
    )
    parser.add_argument(
        '--batch-size', type=int, default=None, help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: config.py ì°¸ì¡°)'
    )
    parser.add_argument(
        '--inference', action='store_true', help='í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ (Inference) ë‹¨ê³„ ìˆ˜í–‰'
    )
    
    return parser.parse_args()


def step_1_setup():
    """ë‹¨ê³„ 1: í™˜ê²½ ì„¤ì •"""
    print_section("[ë‹¨ê³„ 1] í™˜ê²½ ì„¤ì •")
    
    Config.setup_directories()
    Config.print_config()
    
    print_info("í™˜ê²½ ì„¤ì • ì™„ë£Œ")
    
    # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
    workspace_size = FileUtils.get_directory_size(Config.WORKSPACE_ROOT)
    print_info(f"í˜„ì¬ ì‘ì—… ê³µê°„ í¬ê¸°: {workspace_size:.2f} MB")


def step_2_download(skip=False):
    """ë‹¨ê³„ 2: ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
    print_section("[ë‹¨ê³„ 2] ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
    
    if skip:
        print_info("ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë‹¨ê³„ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return True
    
    downloader = DataDownloader()
    
    # ë‹¤ìš´ë¡œë“œ ì‹œë„
    if not downloader.download():
        downloader.wait_for_manual_setup()
    
    # ë°ì´í„° ê²€ì¦
    if not downloader.verify_data():
        print_error("ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨")
        return False
    
    # ë°ì´í„° í†µê³„
    img_count = FileUtils.count_files(Config.IMAGES_DIR, '*.jpg')
    xml_count = FileUtils.count_files(Config.ANNOTATIONS_DIR, '*.xml')
    print_info(f"ì´ë¯¸ì§€ íŒŒì¼: {img_count}ê°œ")
    print_info(f"ì–´ë…¸í…Œì´ì…˜ íŒŒì¼: {xml_count}ê°œ")
    
    return True


def step_3_preprocessing(skip=False):
    """ë‹¨ê³„ 3: ë°ì´í„° ì „ì²˜ë¦¬"""
    print_section("[ë‹¨ê³„ 3] ë°ì´í„° ì „ì²˜ë¦¬")
    
    if skip:
        print_info("ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    
    preprocessor = DataPreprocessor()
    
    # XML íŒŒì‹±
    annotations_df = preprocessor.parse_xml_annotations()
    print_info(f"ì´ {len(annotations_df)}ê°œì˜ ê°ì²´ íŒŒì‹± ì™„ë£Œ")
    
    # í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™”
    try:
        Visualizer.plot_class_distribution(
            annotations_df,
            save_path=Config.PROJECT_DATA_ROOT / 'class_distribution.png'
        )
    except Exception as e:
        print_warning(f"í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™” ì‹¤íŒ¨: {e}")
    
    # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
    resized_annotations_df = preprocessor.resize_images()
    print_info("ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ")
    
    return resized_annotations_df


def step_4_split(annotations_df):
    """ë‹¨ê³„ 4: ë°ì´í„°ì…‹ ë¶„í• """
    print_section("[ë‹¨ê³„ 4] ë°ì´í„°ì…‹ ë¶„í• ")
    
    # ì „ì²˜ë¦¬ ê±´ë„ˆë›°ê¸° ì‹œ, annotations_dfê°€ Noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´ë¥¼ ì²˜ë¦¬
    if annotations_df is None:
        print_error("ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ DataFrameì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None
        
    splitter = DatasetSplitter(annotations_df)
    
    # YOLO í˜•ì‹ ë³€í™˜
    yolo_df = splitter.convert_to_yolo_format()
    print_info("YOLO í˜•ì‹ ë³€í™˜ ì™„ë£Œ")
    
    # ë°ì´í„° ë¶„í• 
    splits = splitter.split_dataset()
    print_info(f"Train: {len(splits['train'])}ì¥")
    print_info(f"Val: {len(splits['val'])}ì¥")
    print_info(f"Test: {len(splits['test'])}ì¥")
    
    # ë¶„í•  ë¹„ìœ¨ ì‹œê°í™”
    try:
        Visualizer.plot_split_distribution(
            splits,
            save_path=Config.PROJECT_DATA_ROOT / 'split_distribution.png'
        )
    except Exception as e:
        print_warning(f"ë¶„í•  ë¹„ìœ¨ ì‹œê°í™” ì‹¤íŒ¨: {e}")
    
    # íŒŒì¼ ì €ì¥
    splitter.save_split_data()
    yaml_path = splitter.create_yaml_file()
    print_info(f"ë°ì´í„°ì…‹ ì €ì¥ ë° YAML íŒŒì¼ ìƒì„± ì™„ë£Œ: {yaml_path}")
    
    return splits


def step_5_training(skip=False, epochs=None, batch_size=None):
    """ë‹¨ê³„ 5: ëª¨ë¸ í•™ìŠµ"""
    print_section("[ë‹¨ê³„ 5] ëª¨ë¸ í•™ìŠµ")
    
    if skip:
        print_info("ëª¨ë¸ í•™ìŠµ ë‹¨ê³„ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None, None
    
    # ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
    if epochs:
        Config.EPOCHS = epochs
        print_info(f"Epochs ë³€ê²½: {epochs}")
    
    if batch_size:
        Config.BATCH_SIZE = batch_size
        print_info(f"Batch Size ë³€ê²½: {batch_size}")
    
    trainer = ModelTrainer()
    model, results = trainer.train()
    
    if model is None:
        print_error("ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨")
        return None, None
    
    print_info("ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    
    return trainer, model


def step_6_visualization(skip=False):
    """ë‹¨ê³„ 6: í•™ìŠµ ê²°ê³¼ ì‹œê°í™”"""
    print_section("[ë‹¨ê³„ 6] í•™ìŠµ ê²°ê³¼ ì‹œê°í™”")
    
    if skip:
        print_info("ì‹œê°í™” ë‹¨ê³„ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    results_dir = Config.RESULTS_DIR / Config.RUN_NAME
    
    if not results_dir.exists():
        print_warning(f"ê²°ê³¼ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {results_dir}")
        return
    
    try:
        Visualizer.show_training_results(results_dir)
        print_info("í•™ìŠµ ê²°ê³¼ ì‹œê°í™” ì™„ë£Œ")
    except Exception as e:
        print_error(f"ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def get_best_model_path(trainer=None, model_path_arg=None):
    """ìµœì  ëª¨ë¸ ê²½ë¡œë¥¼ ê²°ì •í•˜ê³  ë°˜í™˜"""
    if model_path_arg:
        best_model_path = Path(model_path_arg)
        print_info(f"ì§€ì •ëœ ëª¨ë¸ ê²½ë¡œ ì‚¬ìš©: {best_model_path}")
    elif trainer:
        best_model_path = trainer.get_best_model_path()
        print_info(f"í•™ìŠµëœ ìµœê³  ëª¨ë¸ ê²½ë¡œ ì‚¬ìš©: {best_model_path}")
    else:
        # ê¸°ë³¸ ê²½ë¡œì—ì„œ ì°¾ê¸°
        best_model_path = Config.RESULTS_DIR / Config.RUN_NAME / 'weights' / 'best.pt'
        print_info(f"ê¸°ë³¸ ê²½ë¡œì—ì„œ ìµœê³  ëª¨ë¸ ì°¾ê¸°: {best_model_path}")

    if not best_model_path.exists():
        print_error(f"ìµœê³  ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {best_model_path}")
        return None
        
    return best_model_path


def step_7_evaluation(trainer=None, model_path=None):
    """ë‹¨ê³„ 7: Test ì„¸íŠ¸ ìµœì¢… í‰ê°€"""
    print_section("[ë‹¨ê³„ 7] Test ì„¸íŠ¸ ìµœì¢… í‰ê°€")
    
    best_model_path = get_best_model_path(trainer, model_path)
    if best_model_path is None:
        return None

    # í‰ê°€ ìˆ˜í–‰
    evaluator = ModelEvaluator(best_model_path)
    metrics = evaluator.evaluate()
    
    if metrics:
        # ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ ì¶œë ¥
        print_info("--- ìµœì¢… Test ì„¸íŠ¸ ì„±ëŠ¥ ---")
        print_info(f"ğŸš€ mAP@0.5 (ëŠìŠ¨í•œ ê¸°ì¤€): {metrics.get('metrics/mAP50(B)', 'N/A'):.4f}")
        print_info(f"ğŸ¯ mAP@0.5:0.95 (ì—„ê²©í•œ ê¸°ì¤€): {metrics.get('metrics/mAP50-95(B)', 'N/A'):.4f}")
        print_info(f"âœ… Precision: {metrics.get('metrics/precision(B)', 'N/A'):.4f}")
        print_info(f"ğŸ” Recall: {metrics.get('metrics/recall(B)', 'N/A'):.4f}")
        print_info("---------------------------")
    else:
        print_error("ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨. ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
    return best_model_path


def step_8_inference(best_model_path):
    """ë‹¨ê³„ 8: ì¶”ë¡  (ì‹¤ì œ ìš´ì˜ ì‹œë®¬ë ˆì´ì…˜)"""
    print_section("[ë‹¨ê³„ 8] ì¶”ë¡  (Inference)")

    if best_model_path is None:
        print_error("ì¶”ë¡ ì„ ìœ„í•œ ëª¨ë¸ ê²½ë¡œê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # ì¶”ë¡  ìˆ˜í–‰
    inferencer = ModelInference(best_model_path)
    
    # Test ì„¸íŠ¸ì˜ ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤ì„ ëŒ€ìƒìœ¼ë¡œ ì¶”ë¡ 
    input_dir = Config.PROCESSED_DATA_ROOT / 'images' / 'test'
    output_dir = Config.RESULTS_DIR / 'inference_output'
    
    # output_dir ìƒì„±
    output_dir.mkdir(parents=True, exist_ok=True)

    print_info(f"Test ì„¸íŠ¸ ìƒ˜í”Œ ì´ë¯¸ì§€ì— ëŒ€í•´ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    print_info(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_dir}")
    
    inferencer.run_inference(input_dir, output_dir)
    print_info("ì¶”ë¡  ì™„ë£Œ. ê²°ê³¼ëŠ” inference_output í´ë”ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    args = parse_arguments()
    
    print_header()
    
    # 1. í™˜ê²½ ì„¤ì •
    step_1_setup()
    
    # 2. ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    if not args.skip_download and not step_2_download(args.skip_download):
        return

    # 3. ë°ì´í„° ì „ì²˜ë¦¬
    annotations_df = None
    if not args.only_evaluate:
        annotations_df = step_3_preprocessing(args.skip_preprocessing)
    
    # 4. ë°ì´í„°ì…‹ ë¶„í•  (í•™ìŠµ/í‰ê°€ì— í•„ìš”í•œ YAML íŒŒì¼ì´ ì—†ìœ¼ë©´ ì‹¤í–‰)
    if not Config.YAML_PATH.exists() and not args.only_evaluate:
        splits = step_4_split(annotations_df)
        if splits is None:
             return
    
    trainer = None
    best_model_path = None
    
    # 5. ëª¨ë¸ í•™ìŠµ
    if not args.skip_training and not args.only_evaluate:
        trainer, model = step_5_training(
            args.skip_training, 
            args.epochs, 
            args.batch_size
        )
    
    # 6. í•™ìŠµ ê²°ê³¼ ì‹œê°í™”
    step_6_visualization(args.skip_visualization)
    
    # 7. Test ì„¸íŠ¸ ìµœì¢… í‰ê°€
    if args.only_evaluate or (trainer and not args.skip_training):
        best_model_path = step_7_evaluation(trainer, args.model_path)
        
    # 8. ì¶”ë¡  (Inference)
    if args.inference and best_model_path:
        step_8_inference(best_model_path)
        
    print_section("--- í”„ë¡œê·¸ë¨ ì¢…ë£Œ ---")

if __name__ == '__main__':
    main()